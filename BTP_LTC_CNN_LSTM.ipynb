{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5448f1-d27e-4eec-a658-f08c0cccebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals shape: (273, 750, 22)\n",
      "Labels shape: (273,)\n",
      "Unique labels: [769 770 771 772]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('A01T.npz')  \n",
    "signal = data['s']  # Assuming shape is (total_samples, 22)\n",
    "event_types = data['etyp'].T[0]\n",
    "event_positions = data['epos'].T[0]\n",
    "\n",
    "# Initialize empty arrays\n",
    "signals = []\n",
    "trial_types = []\n",
    "valid_labels = {769, 770, 771, 772}\n",
    "\n",
    "for i in range(0, len(event_positions) - 1):\n",
    "    event_type = event_types[i]\n",
    "    next_event_type = event_types[i + 1]\n",
    "    \n",
    "    if event_type == 768 and next_event_type in valid_labels:  # Valid trial start\n",
    "        pos = event_positions[i+1]\n",
    "        \n",
    "        # Extract 750 samples x 22 channels\n",
    "        trial_signal = signal[pos+750 : pos+1500, 0:22]  # All 22 channels\n",
    "        \n",
    "        # Verify the shape is correct\n",
    "        if trial_signal.shape != (750, 22):\n",
    "            print(f\"Unexpected shape at trial {len(signals)}: {trial_signal.shape}\")\n",
    "            continue\n",
    "            \n",
    "        signals.append(trial_signal)\n",
    "        trial_types.append(next_event_type)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "signals_array = np.array(signals)  # Shape (288, 750, 22)\n",
    "labels_array = np.array(trial_types)  # Shape (288,)\n",
    "\n",
    "# Verify final shapes\n",
    "print(\"Signals shape:\", signals_array.shape)\n",
    "print(\"Labels shape:\", labels_array.shape)\n",
    "print(\"Unique labels:\", np.unique(labels_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd60648-d647-469d-bdda-0083b8538eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, trials, labels):\n",
    "        # Trials: (num_trials, 750, 22)\n",
    "        # Labels: (num_trials,)\n",
    "        \n",
    "        # Normalize data per channel\n",
    "        self.data = torch.tensor(trials, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        # Map original labels to 0-3\n",
    "        self.label_mapping = {769: 0, 770: 1, 771: 2, 772: 3}\n",
    "        self.labels = torch.tensor([self.label_mapping[int(x)] for x in labels])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Assuming you have loaded your data into trials and labels arrays\n",
    "trials = np.load('eeg_signals.npy')  # Shape (288, 750, 22)\n",
    "labels = np.load('eeg_labels.npy')     # Shape (288,)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    trials, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EEGDataset(X_train, y_train)\n",
    "test_dataset = EEGDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7501112f-018d-4302-ba42-0d3a7cf73605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleHybridLTC_LSTM(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv1d(22, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (lstm): LSTM(32, 64, batch_first=True)\n",
      "  (ltc_layers): ModuleList(\n",
      "    (0-1): 2 x LTC_Cell(\n",
      "      (W_xh): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (W_hh): Linear(in_features=64, out_features=64, bias=False)\n",
      "      (W_tau): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=32, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LTC_Cell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LTC_Cell, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W_xh = nn.Linear(input_dim, hidden_dim)\n",
    "        self.W_hh = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.W_tau = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        # Compute the time constant tau using a sigmoid and a small constant offset\n",
    "        tau = torch.sigmoid(self.W_tau(h)) + 0.1\n",
    "        # Compute the state derivative\n",
    "        dh = -h / tau + torch.tanh(self.W_xh(x) + self.W_hh(h))\n",
    "        # Update the hidden state with a fixed time step of 0.1\n",
    "        return h + 0.1 * dh\n",
    "\n",
    "class SimpleHybridLTC_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=22, cnn_dim=32, lstm_hidden_dim=64,\n",
    "                 ltc_hidden_dim=64, num_classes=4, num_ltc_layers=1):\n",
    "        super(SimpleHybridLTC_LSTM, self).__init__()\n",
    "        \n",
    "        # CNN block: processes the raw input\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, cnn_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(cnn_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # LSTM block: encodes sequential information from the CNN features\n",
    "        self.lstm = nn.LSTM(input_size=cnn_dim, hidden_size=lstm_hidden_dim, batch_first=True)\n",
    "        \n",
    "        # LTC layers: further process the LSTM output for dynamic temporal behavior\n",
    "        self.ltc_layers = nn.ModuleList([\n",
    "            LTC_Cell(lstm_hidden_dim if i == 0 else ltc_hidden_dim, ltc_hidden_dim)\n",
    "            for i in range(num_ltc_layers)\n",
    "        ])\n",
    "        \n",
    "        # Classifier block: aggregates the processed sequence and outputs class logits\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(ltc_hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is assumed to have the shape: [batch, seq_len, channels]\n",
    "        \n",
    "        # Rearrange to [batch, channels, seq_len] for the CNN layer\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        # Swap back to [batch, seq_len, cnn_dim]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Process the features with the LSTM layer\n",
    "        x, _ = self.lstm(x)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Initialize the LTC layers' hidden state(s)\n",
    "        # Here we support multiple LTC layers; keep each layerâ€™s state separately\n",
    "        h_ltc = [torch.zeros(batch_size, layer.hidden_dim, device=x.device)\n",
    "                 for layer in self.ltc_layers]\n",
    "        \n",
    "        all_hidden = []\n",
    "        # Process the sequence time step by time step with LTC layers\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            for i, ltc_layer in enumerate(self.ltc_layers):\n",
    "                h_ltc[i] = ltc_layer(x_t, h_ltc[i])\n",
    "                x_t = h_ltc[i]\n",
    "            all_hidden.append(x_t)\n",
    "        \n",
    "        # Aggregate temporal information (here using mean pooling)\n",
    "        hidden_stack = torch.stack(all_hidden, dim=1)\n",
    "        pooled = hidden_stack.mean(dim=1)\n",
    "        \n",
    "        # Output the final class predictions\n",
    "        return self.classifier(pooled)\n",
    "\n",
    "# Example instantiation:\n",
    "model = SimpleHybridLTC_LSTM(\n",
    "    input_dim=22,         # For example, the number of EEG channels\n",
    "    cnn_dim=32,           \n",
    "    lstm_hidden_dim=64,  \n",
    "    ltc_hidden_dim=64,   \n",
    "    num_classes=4,        \n",
    "    num_ltc_layers=2      \n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8cc0ba-c157-43e4-bca0-7f34b2541685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting from scratch.\n",
      "Epoch 1/100 | Train Loss: 1.3901 | Val Loss: 1.3855 | Val Acc: 25.00% | Same accuracy streak: 0/10\n",
      "Epoch 2/100 | Train Loss: 1.3875 | Val Loss: 1.3838 | Val Acc: 25.00% | Same accuracy streak: 1/10\n",
      "Epoch 3/100 | Train Loss: 1.3909 | Val Loss: 1.3822 | Val Acc: 25.00% | Same accuracy streak: 2/10\n",
      "Epoch 4/100 | Train Loss: 1.3900 | Val Loss: 1.3816 | Val Acc: 25.00% | Same accuracy streak: 3/10\n",
      "Epoch 5/100 | Train Loss: 1.3859 | Val Loss: 1.3813 | Val Acc: 25.00% | Same accuracy streak: 4/10\n",
      "Epoch 6/100 | Train Loss: 1.3884 | Val Loss: 1.3810 | Val Acc: 25.00% | Same accuracy streak: 5/10\n",
      "Epoch 7/100 | Train Loss: 1.3836 | Val Loss: 1.3800 | Val Acc: 25.00% | Same accuracy streak: 6/10\n",
      "Epoch 8/100 | Train Loss: 1.3855 | Val Loss: 1.3790 | Val Acc: 25.00% | Same accuracy streak: 7/10\n",
      "Epoch 9/100 | Train Loss: 1.3823 | Val Loss: 1.3782 | Val Acc: 27.08% | Same accuracy streak: 0/10\n",
      "Epoch 10/100 | Train Loss: 1.3850 | Val Loss: 1.3772 | Val Acc: 27.08% | Same accuracy streak: 1/10\n",
      "Epoch 11/100 | Train Loss: 1.3850 | Val Loss: 1.3772 | Val Acc: 27.08% | Same accuracy streak: 2/10\n",
      "Epoch 12/100 | Train Loss: 1.3829 | Val Loss: 1.3769 | Val Acc: 27.08% | Same accuracy streak: 3/10\n",
      "Epoch 13/100 | Train Loss: 1.3819 | Val Loss: 1.3764 | Val Acc: 27.08% | Same accuracy streak: 4/10\n",
      "Epoch 14/100 | Train Loss: 1.3927 | Val Loss: 1.3775 | Val Acc: 27.08% | Same accuracy streak: 5/10\n",
      "Epoch 15/100 | Train Loss: 1.3849 | Val Loss: 1.3787 | Val Acc: 20.83% | Same accuracy streak: 0/10\n",
      "Epoch 16/100 | Train Loss: 1.3902 | Val Loss: 1.3796 | Val Acc: 25.00% | Same accuracy streak: 0/10\n",
      "Epoch 17/100 | Train Loss: 1.3844 | Val Loss: 1.3801 | Val Acc: 25.00% | Same accuracy streak: 1/10\n",
      "Epoch 18/100 | Train Loss: 1.3848 | Val Loss: 1.3801 | Val Acc: 25.00% | Same accuracy streak: 2/10\n",
      "Epoch 19/100 | Train Loss: 1.3825 | Val Loss: 1.3798 | Val Acc: 22.92% | Same accuracy streak: 0/10\n",
      "Epoch 20/100 | Train Loss: 1.3863 | Val Loss: 1.3798 | Val Acc: 22.92% | Same accuracy streak: 1/10\n",
      "Epoch 21/100 | Train Loss: 1.3869 | Val Loss: 1.3798 | Val Acc: 27.08% | Same accuracy streak: 0/10\n",
      "Epoch 22/100 | Train Loss: 1.3823 | Val Loss: 1.3797 | Val Acc: 27.08% | Same accuracy streak: 1/10\n",
      "Epoch 23/100 | Train Loss: 1.3836 | Val Loss: 1.3797 | Val Acc: 22.92% | Same accuracy streak: 0/10\n",
      "Epoch 24/100 | Train Loss: 1.3799 | Val Loss: 1.3796 | Val Acc: 27.08% | Same accuracy streak: 0/10\n",
      "Epoch 25/100 | Train Loss: 1.3880 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 1/10\n",
      "Epoch 26/100 | Train Loss: 1.3807 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 2/10\n",
      "Epoch 27/100 | Train Loss: 1.3817 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 3/10\n",
      "Epoch 28/100 | Train Loss: 1.3853 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 4/10\n",
      "Epoch 29/100 | Train Loss: 1.3857 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 5/10\n",
      "Epoch 30/100 | Train Loss: 1.3867 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 6/10\n",
      "Epoch 31/100 | Train Loss: 1.3843 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 7/10\n",
      "Epoch 32/100 | Train Loss: 1.3822 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 8/10\n",
      "Epoch 33/100 | Train Loss: 1.3807 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 9/10\n",
      "Epoch 34/100 | Train Loss: 1.3844 | Val Loss: 1.3795 | Val Acc: 27.08% | Same accuracy streak: 10/10\n",
      "\n",
      "Early stopping triggered after 34 epochs!\n",
      "\n",
      "Training complete. Best validation accuracy: 27.08%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = SimpleHybridLTC_LSTM(\n",
    "    input_dim=22,         # For example, the number of EEG channels\n",
    "    cnn_dim=32,           \n",
    "    lstm_hidden_dim=64,  \n",
    "    ltc_hidden_dim=64,   \n",
    "    num_classes=4,        \n",
    "    num_ltc_layers=1      \n",
    ").to(device)\n",
    "\n",
    "model_path = 'ltc_cnn_lstm_model.pth'\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Loaded model from checkpoint.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting from scratch.\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "num_epochs = 100\n",
    "previous_val_acc = None\n",
    "same_acc_streak = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (data, labels) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "   \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct / total\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(test_loader)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if previous_val_acc is None or val_acc != previous_val_acc:\n",
    "        same_acc_streak = 0  # Reset counter if there's any change in accuracy\n",
    "    else:\n",
    "        same_acc_streak += 1  # Increment counter if accuracy is the same\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'ltc_cnn_lstm_model.pth')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | 'f'Same accuracy streak: {same_acc_streak}/10')\n",
    "\n",
    "    # Early stopping triggered after 10 consecutive epochs with no change in accuracy\n",
    "    if same_acc_streak >= 10:\n",
    "        print(f'\\nEarly stopping triggered after {epoch+1} epochs!')\n",
    "        break\n",
    "    \n",
    "    # Update previous_val_acc for the next iteration\n",
    "    previous_val_acc = val_acc\n",
    "\n",
    "# Load best model and final evaluation\n",
    "print(f'\\nTraining complete. Best validation accuracy: {best_val_acc:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde17cc-02d1-417c-9c11-0e302549e726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
