{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd2ce3e-2dfc-4657-aeb9-906be8c77ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n",
      "Trials shape: (200, 4999, 306)\n",
      "Labels original shape: (1, 200)\n",
      "Labels flattened shape: (200,)\n",
      "Using device: cuda\n",
      "Fold 1/5\n",
      "Train size: 160, Validation size: 40\n",
      "Epoch 1/100 | Train Loss: 1.4263 | Val Loss: 1.5151 | Val Acc: 10.00% | Same accuracy streak: 0/10\n",
      "Epoch 2/100 | Train Loss: 1.4180 | Val Loss: 1.4242 | Val Acc: 10.00% | Same accuracy streak: 1/10\n",
      "Epoch 3/100 | Train Loss: 1.3965 | Val Loss: 1.3991 | Val Acc: 32.50% | Same accuracy streak: 0/10\n",
      "Epoch 4/100 | Train Loss: 1.3953 | Val Loss: 1.4086 | Val Acc: 32.50% | Same accuracy streak: 1/10\n",
      "Epoch 5/100 | Train Loss: 1.3843 | Val Loss: 1.4220 | Val Acc: 10.00% | Same accuracy streak: 0/10\n",
      "Epoch 6/100 | Train Loss: 1.3823 | Val Loss: 1.4374 | Val Acc: 10.00% | Same accuracy streak: 1/10\n",
      "Epoch 7/100 | Train Loss: 1.3946 | Val Loss: 1.4091 | Val Acc: 10.00% | Same accuracy streak: 2/10\n",
      "Epoch 8/100 | Train Loss: 1.3881 | Val Loss: 1.3938 | Val Acc: 27.50% | Same accuracy streak: 0/10\n",
      "Epoch 9/100 | Train Loss: 1.3958 | Val Loss: 1.3805 | Val Acc: 27.50% | Same accuracy streak: 1/10\n",
      "Epoch 10/100 | Train Loss: 1.3938 | Val Loss: 1.3923 | Val Acc: 10.00% | Same accuracy streak: 0/10\n",
      "Epoch 11/100 | Train Loss: 1.3853 | Val Loss: 1.3970 | Val Acc: 10.00% | Same accuracy streak: 1/10\n",
      "Epoch 12/100 | Train Loss: 1.3859 | Val Loss: 1.4027 | Val Acc: 10.00% | Same accuracy streak: 2/10\n",
      "Epoch 13/100 | Train Loss: 1.3851 | Val Loss: 1.4049 | Val Acc: 10.00% | Same accuracy streak: 3/10\n",
      "Epoch 14/100 | Train Loss: 1.3933 | Val Loss: 1.4042 | Val Acc: 10.00% | Same accuracy streak: 4/10\n",
      "Epoch 15/100 | Train Loss: 1.3830 | Val Loss: 1.4012 | Val Acc: 10.00% | Same accuracy streak: 5/10\n",
      "Epoch 16/100 | Train Loss: 1.3908 | Val Loss: 1.4006 | Val Acc: 10.00% | Same accuracy streak: 6/10\n",
      "Epoch 17/100 | Train Loss: 1.3958 | Val Loss: 1.4001 | Val Acc: 10.00% | Same accuracy streak: 7/10\n",
      "Epoch 18/100 | Train Loss: 1.3880 | Val Loss: 1.3993 | Val Acc: 10.00% | Same accuracy streak: 8/10\n",
      "Epoch 19/100 | Train Loss: 1.3765 | Val Loss: 1.3995 | Val Acc: 10.00% | Same accuracy streak: 9/10\n",
      "Epoch 20/100 | Train Loss: 1.3848 | Val Loss: 1.4004 | Val Acc: 10.00% | Same accuracy streak: 10/10\n",
      "Early stopping triggered after 20 epochs!\n",
      "Fold 1 completed with best validation accuracy: 32.50%\n",
      "Average of last 5 epochs: 10.00%\n",
      "Fold 2/5\n",
      "Train size: 160, Validation size: 40\n",
      "Epoch 1/100 | Train Loss: 1.4427 | Val Loss: 1.4367 | Val Acc: 22.50% | Same accuracy streak: 0/10\n",
      "Epoch 2/100 | Train Loss: 1.3908 | Val Loss: 1.4014 | Val Acc: 17.50% | Same accuracy streak: 0/10\n",
      "Epoch 3/100 | Train Loss: 1.3891 | Val Loss: 1.4034 | Val Acc: 22.50% | Same accuracy streak: 0/10\n",
      "Epoch 4/100 | Train Loss: 1.4006 | Val Loss: 1.3986 | Val Acc: 17.50% | Same accuracy streak: 0/10\n",
      "Epoch 5/100 | Train Loss: 1.3962 | Val Loss: 1.4023 | Val Acc: 17.50% | Same accuracy streak: 1/10\n",
      "Epoch 6/100 | Train Loss: 1.3874 | Val Loss: 1.4046 | Val Acc: 17.50% | Same accuracy streak: 2/10\n",
      "Epoch 7/100 | Train Loss: 1.3866 | Val Loss: 1.4015 | Val Acc: 17.50% | Same accuracy streak: 3/10\n",
      "Epoch 8/100 | Train Loss: 1.3848 | Val Loss: 1.4025 | Val Acc: 17.50% | Same accuracy streak: 4/10\n",
      "Epoch 9/100 | Train Loss: 1.3900 | Val Loss: 1.4027 | Val Acc: 17.50% | Same accuracy streak: 5/10\n",
      "Epoch 10/100 | Train Loss: 1.3872 | Val Loss: 1.3989 | Val Acc: 17.50% | Same accuracy streak: 6/10\n",
      "Epoch 11/100 | Train Loss: 1.3859 | Val Loss: 1.3981 | Val Acc: 17.50% | Same accuracy streak: 7/10\n",
      "Epoch 12/100 | Train Loss: 1.3810 | Val Loss: 1.3975 | Val Acc: 17.50% | Same accuracy streak: 8/10\n",
      "Epoch 13/100 | Train Loss: 1.3889 | Val Loss: 1.3968 | Val Acc: 17.50% | Same accuracy streak: 9/10\n",
      "Epoch 14/100 | Train Loss: 1.3851 | Val Loss: 1.3961 | Val Acc: 17.50% | Same accuracy streak: 10/10\n",
      "Early stopping triggered after 14 epochs!\n",
      "Fold 2 completed with best validation accuracy: 22.50%\n",
      "Average of last 5 epochs: 17.50%\n",
      "Fold 3/5\n",
      "Train size: 160, Validation size: 40\n",
      "Epoch 1/100 | Train Loss: 1.4132 | Val Loss: 1.4608 | Val Acc: 15.00% | Same accuracy streak: 0/10\n",
      "Epoch 2/100 | Train Loss: 1.4147 | Val Loss: 1.3887 | Val Acc: 15.00% | Same accuracy streak: 1/10\n",
      "Epoch 3/100 | Train Loss: 1.4080 | Val Loss: 1.3729 | Val Acc: 35.00% | Same accuracy streak: 0/10\n",
      "Epoch 4/100 | Train Loss: 1.3893 | Val Loss: 1.3739 | Val Acc: 35.00% | Same accuracy streak: 1/10\n",
      "Epoch 5/100 | Train Loss: 1.3897 | Val Loss: 1.3959 | Val Acc: 15.00% | Same accuracy streak: 0/10\n",
      "Epoch 6/100 | Train Loss: 1.4031 | Val Loss: 1.4031 | Val Acc: 15.00% | Same accuracy streak: 1/10\n",
      "Epoch 7/100 | Train Loss: 1.3839 | Val Loss: 1.4081 | Val Acc: 15.00% | Same accuracy streak: 2/10\n",
      "Epoch 8/100 | Train Loss: 1.3910 | Val Loss: 1.4158 | Val Acc: 15.00% | Same accuracy streak: 3/10\n",
      "Epoch 9/100 | Train Loss: 1.3934 | Val Loss: 1.4194 | Val Acc: 15.00% | Same accuracy streak: 4/10\n",
      "Epoch 10/100 | Train Loss: 1.3841 | Val Loss: 1.4205 | Val Acc: 15.00% | Same accuracy streak: 5/10\n",
      "Epoch 11/100 | Train Loss: 1.3877 | Val Loss: 1.4207 | Val Acc: 15.00% | Same accuracy streak: 6/10\n",
      "Epoch 12/100 | Train Loss: 1.3819 | Val Loss: 1.4214 | Val Acc: 15.00% | Same accuracy streak: 7/10\n",
      "Epoch 13/100 | Train Loss: 1.3950 | Val Loss: 1.4193 | Val Acc: 15.00% | Same accuracy streak: 8/10\n",
      "Epoch 14/100 | Train Loss: 1.3921 | Val Loss: 1.4191 | Val Acc: 15.00% | Same accuracy streak: 9/10\n",
      "Epoch 15/100 | Train Loss: 1.3811 | Val Loss: 1.4189 | Val Acc: 15.00% | Same accuracy streak: 10/10\n",
      "Early stopping triggered after 15 epochs!\n",
      "Fold 3 completed with best validation accuracy: 35.00%\n",
      "Average of last 5 epochs: 15.00%\n",
      "Fold 4/5\n",
      "Train size: 160, Validation size: 40\n",
      "Epoch 1/100 | Train Loss: 1.4197 | Val Loss: 1.4150 | Val Acc: 17.50% | Same accuracy streak: 0/10\n",
      "Epoch 2/100 | Train Loss: 1.3881 | Val Loss: 1.4276 | Val Acc: 17.50% | Same accuracy streak: 1/10\n",
      "Epoch 3/100 | Train Loss: 1.3815 | Val Loss: 1.4082 | Val Acc: 22.50% | Same accuracy streak: 0/10\n",
      "Epoch 4/100 | Train Loss: 1.3866 | Val Loss: 1.4106 | Val Acc: 22.50% | Same accuracy streak: 1/10\n",
      "Epoch 5/100 | Train Loss: 1.4063 | Val Loss: 1.4112 | Val Acc: 22.50% | Same accuracy streak: 2/10\n",
      "Epoch 6/100 | Train Loss: 1.4014 | Val Loss: 1.4136 | Val Acc: 22.50% | Same accuracy streak: 3/10\n",
      "Epoch 7/100 | Train Loss: 1.3940 | Val Loss: 1.4051 | Val Acc: 22.50% | Same accuracy streak: 4/10\n",
      "Epoch 8/100 | Train Loss: 1.3949 | Val Loss: 1.4029 | Val Acc: 22.50% | Same accuracy streak: 5/10\n",
      "Epoch 9/100 | Train Loss: 1.3853 | Val Loss: 1.4049 | Val Acc: 22.50% | Same accuracy streak: 6/10\n",
      "Epoch 10/100 | Train Loss: 1.3844 | Val Loss: 1.4100 | Val Acc: 22.50% | Same accuracy streak: 7/10\n",
      "Epoch 11/100 | Train Loss: 1.3912 | Val Loss: 1.4115 | Val Acc: 22.50% | Same accuracy streak: 8/10\n",
      "Epoch 12/100 | Train Loss: 1.3894 | Val Loss: 1.4070 | Val Acc: 22.50% | Same accuracy streak: 9/10\n",
      "Epoch 13/100 | Train Loss: 1.3851 | Val Loss: 1.4067 | Val Acc: 17.50% | Same accuracy streak: 0/10\n",
      "Epoch 14/100 | Train Loss: 1.3915 | Val Loss: 1.4020 | Val Acc: 22.50% | Same accuracy streak: 0/10\n",
      "Epoch 15/100 | Train Loss: 1.3879 | Val Loss: 1.4021 | Val Acc: 17.50% | Same accuracy streak: 0/10\n",
      "Epoch 16/100 | Train Loss: 1.3904 | Val Loss: 1.3970 | Val Acc: 22.50% | Same accuracy streak: 0/10\n",
      "Epoch 17/100 | Train Loss: 1.3825 | Val Loss: 1.3988 | Val Acc: 22.50% | Same accuracy streak: 1/10\n",
      "Epoch 18/100 | Train Loss: 1.3825 | Val Loss: 1.4077 | Val Acc: 17.50% | Same accuracy streak: 0/10\n",
      "Epoch 19/100 | Train Loss: 1.3844 | Val Loss: 1.4122 | Val Acc: 17.50% | Same accuracy streak: 1/10\n",
      "Epoch 20/100 | Train Loss: 1.3872 | Val Loss: 1.4134 | Val Acc: 17.50% | Same accuracy streak: 2/10\n",
      "Epoch 21/100 | Train Loss: 1.3821 | Val Loss: 1.4121 | Val Acc: 17.50% | Same accuracy streak: 3/10\n",
      "Epoch 22/100 | Train Loss: 1.3843 | Val Loss: 1.4073 | Val Acc: 17.50% | Same accuracy streak: 4/10\n",
      "Epoch 23/100 | Train Loss: 1.3918 | Val Loss: 1.4074 | Val Acc: 17.50% | Same accuracy streak: 5/10\n",
      "Epoch 24/100 | Train Loss: 1.3778 | Val Loss: 1.4078 | Val Acc: 17.50% | Same accuracy streak: 6/10\n",
      "Epoch 25/100 | Train Loss: 1.3847 | Val Loss: 1.4081 | Val Acc: 17.50% | Same accuracy streak: 7/10\n",
      "Epoch 26/100 | Train Loss: 1.3874 | Val Loss: 1.4082 | Val Acc: 17.50% | Same accuracy streak: 8/10\n",
      "Epoch 27/100 | Train Loss: 1.3844 | Val Loss: 1.4083 | Val Acc: 17.50% | Same accuracy streak: 9/10\n",
      "Epoch 28/100 | Train Loss: 1.3916 | Val Loss: 1.4077 | Val Acc: 17.50% | Same accuracy streak: 10/10\n",
      "Early stopping triggered after 28 epochs!\n",
      "Fold 4 completed with best validation accuracy: 22.50%\n",
      "Average of last 5 epochs: 17.50%\n",
      "Fold 5/5\n",
      "Train size: 160, Validation size: 40\n",
      "Epoch 1/100 | Train Loss: 1.4083 | Val Loss: 1.4048 | Val Acc: 27.50% | Same accuracy streak: 0/10\n",
      "Epoch 2/100 | Train Loss: 1.4096 | Val Loss: 1.4139 | Val Acc: 25.00% | Same accuracy streak: 0/10\n",
      "Epoch 3/100 | Train Loss: 1.3910 | Val Loss: 1.4205 | Val Acc: 15.00% | Same accuracy streak: 0/10\n",
      "Epoch 4/100 | Train Loss: 1.3909 | Val Loss: 1.4353 | Val Acc: 15.00% | Same accuracy streak: 1/10\n",
      "Epoch 5/100 | Train Loss: 1.3873 | Val Loss: 1.4304 | Val Acc: 15.00% | Same accuracy streak: 2/10\n",
      "Epoch 6/100 | Train Loss: 1.3857 | Val Loss: 1.4269 | Val Acc: 15.00% | Same accuracy streak: 3/10\n",
      "Epoch 7/100 | Train Loss: 1.3837 | Val Loss: 1.4223 | Val Acc: 15.00% | Same accuracy streak: 4/10\n",
      "Epoch 8/100 | Train Loss: 1.3850 | Val Loss: 1.4218 | Val Acc: 15.00% | Same accuracy streak: 5/10\n",
      "Epoch 9/100 | Train Loss: 1.3887 | Val Loss: 1.4214 | Val Acc: 15.00% | Same accuracy streak: 6/10\n",
      "Epoch 10/100 | Train Loss: 1.3858 | Val Loss: 1.4210 | Val Acc: 15.00% | Same accuracy streak: 7/10\n",
      "Epoch 11/100 | Train Loss: 1.3864 | Val Loss: 1.4204 | Val Acc: 15.00% | Same accuracy streak: 8/10\n",
      "Epoch 12/100 | Train Loss: 1.3835 | Val Loss: 1.4197 | Val Acc: 15.00% | Same accuracy streak: 9/10\n",
      "Epoch 13/100 | Train Loss: 1.3831 | Val Loss: 1.4190 | Val Acc: 15.00% | Same accuracy streak: 10/10\n",
      "Early stopping triggered after 13 epochs!\n",
      "Fold 5 completed with best validation accuracy: 27.50%\n",
      "Average of last 5 epochs: 15.00%\n",
      "\n",
      "===== Cross-Validation Results =====\n",
      "Individual fold accuracies: ['32.50%', '22.50%', '35.00%', '22.50%', '27.50%']\n",
      "Average validation accuracy across 5 folds: 28.00% ± 5.10%\n",
      "Best fold accuracy: 35.00%\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import os\n",
    "\n",
    "# Step 1: Load and process the MEG data\n",
    "file_path = r\"D:\\BTP\\sub-1_ses-1_task-bcimici_meg.mat\"\n",
    "\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    data = f['dataMAT']\n",
    "    trial_refs = data['trial']\n",
    "    trial_info_array = data['trialinfo'][:]  # Directly load trialinfo\n",
    "    \n",
    "    trials_list = []\n",
    "    \n",
    "    for i in range(200):\n",
    "        trial_ref = trial_refs[i,0]\n",
    "        trial_data = f[trial_ref][2001:7001]  # (channels, timepoints)\n",
    "        trials_list.append(trial_data)\n",
    "\n",
    "# Convert trials list to array\n",
    "trials_array = np.array(trials_list)\n",
    "print(trial_info_array.shape)  # Should now show (200, 1)\n",
    "\n",
    "# Save to .npy files\n",
    "np.save(r\"meg_trials.npy\", trials_array)\n",
    "np.save(r\"meg_trial_info.npy\", trial_info_array)\n",
    "\n",
    "# Step 2: Create a custom dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, trials, labels):\n",
    "        # Trials: (num_trials, channels, timepoints)\n",
    "        # Labels: (num_trials,)\n",
    "        \n",
    "        # Normalize data per channel\n",
    "        self.data = torch.tensor(trials, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        # Map original labels to 0-3\n",
    "        self.label_mapping = {1: 0, 2: 1, 3: 2, 4: 3}\n",
    "        self.labels = torch.tensor([self.label_mapping[int(x)] for x in labels])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Step 3: Load the processed data\n",
    "trials = np.load('meg_trials.npy')  # Shape (200, 5000, 306)\n",
    "labels = np.load('meg_trial_info.npy')\n",
    "print(f\"Trials shape: {trials.shape}\")\n",
    "print(f\"Labels original shape: {labels.shape}\")\n",
    "labels = labels.reshape(-1)  # Flatten labels for stratification\n",
    "print(f\"Labels flattened shape: {labels.shape}\")\n",
    "\n",
    "# Step 4: Define the LTC network model\n",
    "class LTC_Cell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LTC_Cell, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W_xh = nn.Linear(input_dim, hidden_dim)\n",
    "        self.W_hh = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.W_tau = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        tau = torch.sigmoid(self.W_tau(h)) + 0.1\n",
    "        dh = -h / tau + torch.tanh(self.W_xh(x) + self.W_hh(h))\n",
    "        return h + 0.1 * dh\n",
    "\n",
    "class LTC_Transformer(nn.Module):\n",
    "    def __init__(self, input_dim=22, ltc_hidden_dim=64, num_classes=4, \n",
    "                 num_ltc_layers=1, num_transformer_layers=1, nhead=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.ltc_hidden_dim = ltc_hidden_dim\n",
    "        self.num_ltc_layers = num_ltc_layers\n",
    "        \n",
    "        # LTC layers\n",
    "        self.ltc_layers = nn.ModuleList([\n",
    "            LTC_Cell(input_dim if i==0 else ltc_hidden_dim, ltc_hidden_dim)\n",
    "            for i in range(num_ltc_layers)\n",
    "        ])\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=ltc_hidden_dim, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=ltc_hidden_dim*2,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=num_transformer_layers\n",
    "        )\n",
    "        \n",
    "        # Classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(ltc_hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, input_dim]\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Initialize hidden states\n",
    "        hiddens = [torch.zeros(batch_size, self.ltc_hidden_dim, device=x.device) \n",
    "                  for _ in range(self.num_ltc_layers)]\n",
    "        \n",
    "        # Process sequence through LTC layers\n",
    "        all_hidden = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            for layer_idx in range(self.num_ltc_layers):\n",
    "                hiddens[layer_idx] = self.ltc_layers[layer_idx](\n",
    "                    x_t if layer_idx == 0 else hiddens[layer_idx-1],\n",
    "                    hiddens[layer_idx]\n",
    "                )\n",
    "            all_hidden.append(hiddens[-1])\n",
    "        \n",
    "        # Stack hidden states for transformer input\n",
    "        hidden_stack = torch.stack(all_hidden, dim=1)  # [batch_size, seq_len, ltc_hidden_dim]\n",
    "        \n",
    "        # Pass through transformer\n",
    "        transformer_out = self.transformer(hidden_stack)\n",
    "        \n",
    "        # Global average pooling\n",
    "        pooled = transformer_out.mean(dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        return self.classifier(pooled)\n",
    "\n",
    "# Step 5: Prepare for training with 5-fold cross-validation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare the full dataset\n",
    "full_dataset = EEGDataset(trials, labels)\n",
    "\n",
    "# KFold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Setup\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Store results across folds\n",
    "fold_results = []\n",
    "\n",
    "# Step 6: Implement 5-fold cross-validation training\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(full_dataset)))):\n",
    "    print(f'Fold {fold+1}/5')\n",
    "    print(f'Train size: {len(train_idx)}, Validation size: {len(val_idx)}')\n",
    "    \n",
    "    # Create data subsets for this fold\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize a fresh model for this fold\n",
    "    model = LTC_Transformer(\n",
    "    input_dim=306,               # Number of EEG channels\n",
    "    ltc_hidden_dim=64,          # LTC hidden dimension (reduced)\n",
    "    num_classes=4,              # Number of classes to predict\n",
    "    num_ltc_layers=1,           # Single LTC layer for simplicity\n",
    "    num_transformer_layers=1,   # Single transformer layer\n",
    "    nhead=2,                    # Fewer attention heads\n",
    "    dropout=0.5                 # Dropout for regularization\n",
    "    ).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "    \n",
    "    # Training variables\n",
    "    best_val_acc = 0\n",
    "    previous_val_acc = None\n",
    "    same_acc_streak = 0\n",
    "    val_acc_list = []\n",
    "    \n",
    "    # Training loop for this fold\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in val_loader:\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "                outputs = model(data)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * correct / total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if previous_val_acc is None or val_acc != previous_val_acc:\n",
    "            same_acc_streak = 0\n",
    "        else:\n",
    "            same_acc_streak += 1\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # Save model for this fold\n",
    "            torch.save(model.state_dict(), f'meg_ltc_TRAN_model_fold{fold+1}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Same accuracy streak: {same_acc_streak}/10')\n",
    "        \n",
    "        if same_acc_streak >= 10:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs!')\n",
    "            break\n",
    "        \n",
    "        previous_val_acc = val_acc\n",
    "    \n",
    "    # Calculate and store the average of the last 5 validation accuracies for this fold\n",
    "    avg_val_acc = sum(val_acc_list[-5:]) / min(5, len(val_acc_list))\n",
    "    fold_results.append(best_val_acc)\n",
    "    print(f'Fold {fold+1} completed with best validation accuracy: {best_val_acc:.2f}%')\n",
    "    print(f'Average of last 5 epochs: {avg_val_acc:.2f}%')\n",
    "\n",
    "# Step 7: Report overall cross-validation results\n",
    "avg_acc = sum(fold_results) / len(fold_results)\n",
    "std_acc = np.std(fold_results)\n",
    "print(\"\\n===== Cross-Validation Results =====\")\n",
    "print(f'Individual fold accuracies: {[f\"{acc:.2f}%\" for acc in fold_results]}')\n",
    "print(f'Average validation accuracy across 5 folds: {avg_acc:.2f}% ± {std_acc:.2f}%')\n",
    "print(f'Best fold accuracy: {max(fold_results):.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b66ba7-8173-4f4c-83b9-2036150b9e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
